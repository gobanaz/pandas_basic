{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 깔끔한 데이터\n",
    "    7-1 열과 피벗\n",
    "    7-2 열 이름 관리\n",
    "    7-3 여러 열 하나로 정리\n",
    "    7-4 중복 데이터 처리\n",
    "    7-5 대용량 데이터 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-1 열과 피벗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터프레임의 열 : 파이썬의 변수와 비슷한 역할\n",
    "    #ex) ebola 데이터프레임 열 : 사망날짜(Date), 발병국(Case_Guinea) 등 데이터 저장\n",
    "    \n",
    "# 넓은 데이터 : 데이터프레임의 열 자체가 값을 의미\n",
    "    #ex) 넓은 데이터 열 : <10$, <10-20$, <20-30$, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### melt 메서드 : 데이터프레임 정리에 유용한 메서드\n",
    "    melt 메서드 인자\n",
    "        id_vars : 위치를 그대로 유지할 열의 이름 지정\n",
    "        value_vars : 행으로 위치를 변경할 열의 이름 지정\n",
    "        var_name : value_vars로 위치를 변경할 열 이름 지정\n",
    "        value_name : var_name으로 위치 변경할 열의 데이터를 저장할 열 이름 지정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1개의 열만 고정하고 나머지 열을 행으로 바꾸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             religion  <$10k  $10-20k  $20-30k  $30-40k  $40-50k  $50-75k  \\\n",
      "0            Agnostic     27       34       60       81       76      137   \n",
      "1             Atheist     12       27       37       52       35       70   \n",
      "2            Buddhist     27       21       30       34       33       58   \n",
      "3            Catholic    418      617      732      670      638     1116   \n",
      "4  Don’t know/refused     15       14       15       11       10       35   \n",
      "\n",
      "   $75-100k  $100-150k  >150k  Don't know/refused  \n",
      "0       122        109     84                  96  \n",
      "1        73         59     74                  76  \n",
      "2        62         39     53                  54  \n",
      "3       949        792    633                1489  \n",
      "4        21         17     18                 116  \n"
     ]
    }
   ],
   "source": [
    "# melt 메서드 사용 : 11개의 넓은데이터 데이터프레임 예시\n",
    "import pandas as pd\n",
    "pew = pd.read_csv('./data/pew.csv')\n",
    "print(pew.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   religion  <$10k  $10-20k  $20-30k  $30-40k  $40-50k\n",
      "0                  Agnostic     27       34       60       81       76\n",
      "1                   Atheist     12       27       37       52       35\n",
      "2                  Buddhist     27       21       30       34       33\n",
      "3                  Catholic    418      617      732      670      638\n",
      "4        Don’t know/refused     15       14       15       11       10\n",
      "5          Evangelical Prot    575      869     1064      982      881\n",
      "6                     Hindu      1        9        7        9       11\n",
      "7   Historically Black Prot    228      244      236      238      197\n",
      "8         Jehovah's Witness     20       27       24       24       21\n",
      "9                    Jewish     19       19       25       25       30\n",
      "10            Mainline Prot    289      495      619      655      651\n",
      "11                   Mormon     29       40       48       51       56\n",
      "12                   Muslim      6        7        9       10        9\n",
      "13                 Orthodox     13       17       23       32       32\n",
      "14          Other Christian      9        7       11       13       13\n",
      "15             Other Faiths     20       33       40       46       49\n",
      "16    Other World Religions      5        2        3        4        2\n",
      "17             Unaffiliated    217      299      374      365      341\n"
     ]
    }
   ],
   "source": [
    "# 6열까지만\n",
    "print(pew.iloc[:, 0:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             religion variable  value\n",
      "0            Agnostic    <$10k     27\n",
      "1             Atheist    <$10k     12\n",
      "2            Buddhist    <$10k     27\n",
      "3            Catholic    <$10k    418\n",
      "4  Don’t know/refused    <$10k     15\n",
      "                  religion            variable  value\n",
      "0                 Agnostic               <$10k     27\n",
      "1                  Atheist               <$10k     12\n",
      "2                 Buddhist               <$10k     27\n",
      "3                 Catholic               <$10k    418\n",
      "4       Don’t know/refused               <$10k     15\n",
      "..                     ...                 ...    ...\n",
      "175               Orthodox  Don't know/refused     73\n",
      "176        Other Christian  Don't know/refused     18\n",
      "177           Other Faiths  Don't know/refused     71\n",
      "178  Other World Religions  Don't know/refused      8\n",
      "179           Unaffiliated  Don't know/refused    597\n",
      "\n",
      "[180 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# 종교와 소득정보 출력됨\n",
    "    # 소득정보 열을 행데이터로 옮기고 싶다면?\n",
    "pew_long = pd.melt(pew, id_vars='religion')\n",
    "print(pew_long.head())\n",
    "#소득 정보 열이 행데이터(value)열로 정리됨\n",
    "    # religion열을 고정하여 피벗했다 라고 표현함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### varibale, value 열 이름 바꾸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             religion income  count\n",
      "0            Agnostic  <$10k     27\n",
      "1             Atheist  <$10k     12\n",
      "2            Buddhist  <$10k     27\n",
      "3            Catholic  <$10k    418\n",
      "4  Don’t know/refused  <$10k     15\n"
     ]
    }
   ],
   "source": [
    "#variable > income, value > count 로 columns명 변경\n",
    "pew_long = pd.melt(pew, id_vars='religion', var_name='income', value_name='count')\n",
    "print(pew_long.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2개 이상의 열 고정, 나머지 열을 행으로 바꾸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year        artist                    track  time date.entered  wk1   wk2  \\\n",
      "0  2000         2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26   87  82.0   \n",
      "1  2000       2Ge+her  The Hardest Part Of ...  3:15   2000-09-02   91  87.0   \n",
      "2  2000  3 Doors Down               Kryptonite  3:53   2000-04-08   81  70.0   \n",
      "3  2000  3 Doors Down                    Loser  4:24   2000-10-21   76  76.0   \n",
      "4  2000      504 Boyz            Wobble Wobble  3:35   2000-04-15   57  34.0   \n",
      "\n",
      "    wk3   wk4   wk5   wk6   wk7   wk8   wk9  wk10  wk11  \n",
      "0  72.0  77.0  87.0  94.0  99.0   NaN   NaN   NaN   NaN  \n",
      "1  92.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "2  68.0  67.0  66.0  57.0  54.0  53.0  51.0  51.0  51.0  \n",
      "3  72.0  69.0  67.0  65.0  55.0  59.0  62.0  61.0  61.0  \n",
      "4  25.0  17.0  17.0  31.0  36.0  49.0  53.0  57.0  64.0  \n"
     ]
    }
   ],
   "source": [
    "billboard = pd.read_csv('./data/billboard.csv')\n",
    "print(billboard.iloc[0:5, 0:16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year        artist                    track  time date.entered week  rating\n",
      "0  2000         2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26  wk1    87.0\n",
      "1  2000       2Ge+her  The Hardest Part Of ...  3:15   2000-09-02  wk1    91.0\n",
      "2  2000  3 Doors Down               Kryptonite  3:53   2000-04-08  wk1    81.0\n",
      "3  2000  3 Doors Down                    Loser  4:24   2000-10-21  wk1    76.0\n",
      "4  2000      504 Boyz            Wobble Wobble  3:35   2000-04-15  wk1    57.0\n"
     ]
    }
   ],
   "source": [
    "# year, artist, track, time, date.entered 열 고정\n",
    "    #나머지열(wk1, wk2,...) 피벗\n",
    "billboard_long = pd.melt(billboard, id_vars=['year', 'artist', 'track', 'time', 'date.entered'],\n",
    "                         var_name = 'week', value_name='rating')\n",
    "print(billboard_long.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-2 열 이름 관리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 하나의 열이 여러 의미를 가질때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Date', 'Day', 'Cases_Guinea', 'Cases_Liberia', 'Cases_SierraLeone',\n",
      "       'Cases_Nigeria', 'Cases_Senegal', 'Cases_UnitedStates', 'Cases_Spain',\n",
      "       'Cases_Mali', 'Deaths_Guinea', 'Deaths_Liberia', 'Deaths_SierraLeone',\n",
      "       'Deaths_Nigeria', 'Deaths_Senegal', 'Deaths_UnitedStates',\n",
      "       'Deaths_Spain', 'Deaths_Mali'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#ebola df의 Deaths_Guinea열은 '사망자수'와 '나라이름'을 합쳐 만든 이름\n",
    "ebola = pd.read_csv('./data/country_timeseries.csv')\n",
    "print(ebola.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Day  Cases_Guinea  Cases_Liberia  Deaths_Guinea  Deaths_Liberia\n",
      "0    1/5/2015  289        2776.0            NaN         1786.0             NaN\n",
      "1    1/4/2015  288        2775.0            NaN         1781.0             NaN\n",
      "2    1/3/2015  287        2769.0         8166.0         1767.0          3496.0\n",
      "3    1/2/2015  286           NaN         8157.0            NaN          3496.0\n",
      "4  12/31/2014  284        2730.0         8115.0         1739.0          3471.0\n"
     ]
    }
   ],
   "source": [
    "print(ebola.iloc[:5, [0, 1, 2, 3, 10, 11]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Date  Day      variable   value\n",
      "0       1/5/2015  289  Cases_Guinea  2776.0\n",
      "1       1/4/2015  288  Cases_Guinea  2775.0\n",
      "2       1/3/2015  287  Cases_Guinea  2769.0\n",
      "3       1/2/2015  286  Cases_Guinea     NaN\n",
      "4     12/31/2014  284  Cases_Guinea  2730.0\n",
      "...          ...  ...           ...     ...\n",
      "1947   3/27/2014    5   Deaths_Mali     NaN\n",
      "1948   3/26/2014    4   Deaths_Mali     NaN\n",
      "1949   3/25/2014    3   Deaths_Mali     NaN\n",
      "1950   3/24/2014    2   Deaths_Mali     NaN\n",
      "1951   3/22/2014    0   Deaths_Mali     NaN\n",
      "\n",
      "[1952 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "#Date와 Day고정 나머지를 행으로 피벗 > 각 나라별 사망자수를 행으로 볼 수 있어짐\n",
    "ebola_long = pd.melt(ebola, id_vars=['Date', 'Day'])\n",
    "print(ebola_long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### split 메서드로 열 이름 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       [Cases, Guinea]\n",
      "1       [Cases, Guinea]\n",
      "2       [Cases, Guinea]\n",
      "3       [Cases, Guinea]\n",
      "4       [Cases, Guinea]\n",
      "             ...       \n",
      "1947     [Deaths, Mali]\n",
      "1948     [Deaths, Mali]\n",
      "1949     [Deaths, Mali]\n",
      "1950     [Deaths, Mali]\n",
      "1951     [Deaths, Mali]\n",
      "Name: variable, Length: 1952, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Cases_Guinea 같이 언더바(_)로 구분되어 2개 이상의 의미를 가진 열 split으로 분리\n",
    "variable_split = ebola_long.variable.str.split('_')\n",
    "print(variable_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(variable_split))\n",
    "print(type(variable_split[0]))\n",
    "#variable_split의 자료형은 시리즈, 각 시리즈 값은 리스트형태"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Cases\n",
      "1    Cases\n",
      "2    Cases\n",
      "3    Cases\n",
      "4    Cases\n",
      "Name: variable, dtype: object\n",
      "1947    Deaths\n",
      "1948    Deaths\n",
      "1949    Deaths\n",
      "1950    Deaths\n",
      "1951    Deaths\n",
      "Name: variable, dtype: object\n",
      "0    Guinea\n",
      "1    Guinea\n",
      "2    Guinea\n",
      "3    Guinea\n",
      "4    Guinea\n",
      "Name: variable, dtype: object\n",
      "1947    Mali\n",
      "1948    Mali\n",
      "1949    Mali\n",
      "1950    Mali\n",
      "1951    Mali\n",
      "Name: variable, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#각 리스트의 0번째 인덱스는 발병(Cases)/죽음(Death)와 같은 상태를 의미\n",
    "    #1번째 인덱스는 나라이름\n",
    "status_values = variable_split.str.get(0)\n",
    "country_values = variable_split.str.get(1)\n",
    "\n",
    "print(status_values[:5])\n",
    "print(status_values[-5:])\n",
    "print(country_values[:5])\n",
    "print(country_values[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Day      variable   value status country\n",
      "0    1/5/2015  289  Cases_Guinea  2776.0  Cases  Guinea\n",
      "1    1/4/2015  288  Cases_Guinea  2775.0  Cases  Guinea\n",
      "2    1/3/2015  287  Cases_Guinea  2769.0  Cases  Guinea\n",
      "3    1/2/2015  286  Cases_Guinea     NaN  Cases  Guinea\n",
      "4  12/31/2014  284  Cases_Guinea  2730.0  Cases  Guinea\n"
     ]
    }
   ],
   "source": [
    "ebola_long['status'] = status_values\n",
    "ebola_long['country'] = country_values\n",
    "print(ebola_long.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Day      variable   value status country status country\n",
      "0    1/5/2015  289  Cases_Guinea  2776.0  Cases  Guinea  Cases  Guinea\n",
      "1    1/4/2015  288  Cases_Guinea  2775.0  Cases  Guinea  Cases  Guinea\n",
      "2    1/3/2015  287  Cases_Guinea  2769.0  Cases  Guinea  Cases  Guinea\n",
      "3    1/2/2015  286  Cases_Guinea     NaN  Cases  Guinea  Cases  Guinea\n",
      "4  12/31/2014  284  Cases_Guinea  2730.0  Cases  Guinea  Cases  Guinea\n"
     ]
    }
   ],
   "source": [
    "# 참고) concat 메서드로 데이터프레임 열 추가하는 방법\n",
    "variable_split = ebola_long.variable.str.split('_', expand=True)\n",
    "variable_split.columns = ['status', 'country']\n",
    "ebola_parsed = pd.concat([ebola_long, variable_split], axis=1)\n",
    "\n",
    "print(ebola_parsed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [Cases, Guinea]\n",
      "1    [Cases, Guinea]\n",
      "2    [Cases, Guinea]\n",
      "3    [Cases, Guinea]\n",
      "4    [Cases, Guinea]\n",
      "Name: variable, dtype: object\n"
     ]
    }
   ],
   "source": [
    "variable_split = ebola_long.variable.str.split('_', expand=False)\n",
    "print(variable_split.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-3 여러 열 하나로 정리 - melt, pivot_table 메서드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  year  month element  d1    d2    d3  d4    d5  d6  ...  d22   d23  \\\n",
      "0  MX17004  2010      1    tmax NaN   NaN   NaN NaN   NaN NaN  ...  NaN   NaN   \n",
      "1  MX17004  2010      1    tmin NaN   NaN   NaN NaN   NaN NaN  ...  NaN   NaN   \n",
      "2  MX17004  2010      2    tmax NaN  27.3  24.1 NaN   NaN NaN  ...  NaN  29.9   \n",
      "3  MX17004  2010      2    tmin NaN  14.4  14.4 NaN   NaN NaN  ...  NaN  10.7   \n",
      "4  MX17004  2010      3    tmax NaN   NaN   NaN NaN  32.1 NaN  ...  NaN   NaN   \n",
      "\n",
      "   d24  d25  d26  d27  d28  d29   d30  d31  \n",
      "0  NaN  NaN  NaN  NaN  NaN  NaN  27.8  NaN  \n",
      "1  NaN  NaN  NaN  NaN  NaN  NaN  14.5  NaN  \n",
      "2  NaN  NaN  NaN  NaN  NaN  NaN   NaN  NaN  \n",
      "3  NaN  NaN  NaN  NaN  NaN  NaN   NaN  NaN  \n",
      "4  NaN  NaN  NaN  NaN  NaN  NaN   NaN  NaN  \n",
      "\n",
      "[5 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "weather = pd.read_csv('./data/weather.csv')\n",
    "print(weather.iloc[:5, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  year  month element day  temp\n",
      "0  MX17004  2010      1    tmax  d1   NaN\n",
      "1  MX17004  2010      1    tmin  d1   NaN\n",
      "2  MX17004  2010      2    tmax  d1   NaN\n",
      "3  MX17004  2010      2    tmin  d1   NaN\n",
      "4  MX17004  2010      3    tmax  d1   NaN\n"
     ]
    }
   ],
   "source": [
    "#가로로 나열된 열들을 행값으로 변경\n",
    "weather_melt = pd.melt(\n",
    "    weather, \n",
    "    id_vars=['id', 'year', 'month', 'element'], #고정시킬 열\n",
    "    var_name='day', #행으로 모을 열들의 컬럼명\n",
    "    value_name='temp'\n",
    "    )  #행으로 모을 열들의 값 컬럼명\n",
    "print(weather_melt.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "element                 tmax  tmin\n",
      "id      year month day            \n",
      "MX17004 2010 1     d1    NaN   NaN\n",
      "                   d10   NaN   NaN\n",
      "                   d11   NaN   NaN\n",
      "                   d12   NaN   NaN\n",
      "                   d13   NaN   NaN\n",
      "...                      ...   ...\n",
      "             12    d5    NaN   NaN\n",
      "                   d6   27.8  10.5\n",
      "                   d7    NaN   NaN\n",
      "                   d8    NaN   NaN\n",
      "                   d9    NaN   NaN\n",
      "\n",
      "[341 rows x 2 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# 열로 나타내고싶은 행데이터(element)를 위치변경\n",
    "weather_tidy = weather_melt.pivot_table(\n",
    "    index =['id', 'year', 'month', 'day'],   #고정시킬열\n",
    "    columns = 'element', #열로 나열할 행\n",
    "    values = 'temp', #열이 된 변수의 값들\n",
    "    dropna = False\n",
    ")\n",
    "print(weather_tidy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "element       id  year  month  day  tmax  tmin\n",
      "0        MX17004  2010      1   d1   NaN   NaN\n",
      "1        MX17004  2010      1  d10   NaN   NaN\n",
      "2        MX17004  2010      1  d11   NaN   NaN\n",
      "3        MX17004  2010      1  d12   NaN   NaN\n",
      "4        MX17004  2010      1  d13   NaN   NaN\n",
      "..           ...   ...    ...  ...   ...   ...\n",
      "336      MX17004  2010     12   d5   NaN   NaN\n",
      "337      MX17004  2010     12   d6  27.8  10.5\n",
      "338      MX17004  2010     12   d7   NaN   NaN\n",
      "339      MX17004  2010     12   d8   NaN   NaN\n",
      "340      MX17004  2010     12   d9   NaN   NaN\n",
      "\n",
      "[341 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "#reset_index로 변경한 pivot_table을 데이터프레임화\n",
    "weather_tidy_flat = weather_tidy.reset_index()\n",
    "print(weather_tidy_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-4 중복 데이터 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year        artist                    track  time date.entered  wk1   wk2  \\\n",
      "0  2000         2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26   87  82.0   \n",
      "1  2000       2Ge+her  The Hardest Part Of ...  3:15   2000-09-02   91  87.0   \n",
      "2  2000  3 Doors Down               Kryptonite  3:53   2000-04-08   81  70.0   \n",
      "3  2000  3 Doors Down                    Loser  4:24   2000-10-21   76  76.0   \n",
      "4  2000      504 Boyz            Wobble Wobble  3:35   2000-04-15   57  34.0   \n",
      "\n",
      "    wk3   wk4   wk5  ...  wk67  wk68  wk69  wk70  wk71  wk72  wk73  wk74  \\\n",
      "0  72.0  77.0  87.0  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "1  92.0   NaN   NaN  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "2  68.0  67.0  66.0  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "3  72.0  69.0  67.0  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "4  25.0  17.0  17.0  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "\n",
      "   wk75  wk76  \n",
      "0   NaN   NaN  \n",
      "1   NaN   NaN  \n",
      "2   NaN   NaN  \n",
      "3   NaN   NaN  \n",
      "4   NaN   NaN  \n",
      "\n",
      "[5 rows x 81 columns]\n"
     ]
    }
   ],
   "source": [
    "billboard = pd.read_csv('./data/billboard.csv')\n",
    "print(billboard.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24092, 7)\n",
      "   year        artist                    track  time date.entered week  rating\n",
      "0  2000         2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26  wk1    87.0\n",
      "1  2000       2Ge+her  The Hardest Part Of ...  3:15   2000-09-02  wk1    91.0\n",
      "2  2000  3 Doors Down               Kryptonite  3:53   2000-04-08  wk1    81.0\n",
      "3  2000  3 Doors Down                    Loser  4:24   2000-10-21  wk1    76.0\n",
      "4  2000      504 Boyz            Wobble Wobble  3:35   2000-04-15  wk1    57.0\n"
     ]
    }
   ],
   "source": [
    "billboard_melt = pd.melt(\n",
    "    billboard, \n",
    "    id_vars = ['year', 'artist' ,'track' ,'time' ,'date.entered'],\n",
    "    var_name = 'week',\n",
    "    value_name = 'rating'\n",
    "    )\n",
    "\n",
    "print(billboard_long.shape)\n",
    "print(billboard_long.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      year        artist  track  time date.entered week  rating\n",
      "3     2000  3 Doors Down  Loser  4:24   2000-10-21  wk1    76.0\n",
      "320   2000  3 Doors Down  Loser  4:24   2000-10-21  wk2    76.0\n",
      "637   2000  3 Doors Down  Loser  4:24   2000-10-21  wk3    72.0\n",
      "954   2000  3 Doors Down  Loser  4:24   2000-10-21  wk4    69.0\n",
      "1271  2000  3 Doors Down  Loser  4:24   2000-10-21  wk5    67.0\n"
     ]
    }
   ],
   "source": [
    "#track에 Loser라는 노래 데이터가 여러개임을 확인, week/rating을 제외하면 다른행들은 같은데이터를 지님\n",
    "print(billboard_long[billboard_long.track == 'Loser'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24092, 4)\n"
     ]
    }
   ],
   "source": [
    "#중복값을 갖는 열을 따로모아 데이터프레임에 저장\n",
    "billboard_songs = billboard_long[['year', 'artist', 'track', 'time']]\n",
    "print(billboard_songs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(317, 4)\n"
     ]
    }
   ],
   "source": [
    "#drop_duplicates로 데이터프레임 중복데이터 제거\n",
    "billboard_songs = billboard_songs.drop_duplicates()\n",
    "print(billboard_songs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year          artist                    track  time  id\n",
      "0  2000           2 Pac  Baby Don't Cry (Keep...  4:22   0\n",
      "1  2000         2Ge+her  The Hardest Part Of ...  3:15   1\n",
      "2  2000    3 Doors Down               Kryptonite  3:53   2\n",
      "3  2000    3 Doors Down                    Loser  4:24   3\n",
      "4  2000        504 Boyz            Wobble Wobble  3:35   4\n",
      "5  2000            98^0  Give Me Just One Nig...  3:24   5\n",
      "6  2000         A*Teens            Dancing Queen  3:44   6\n",
      "7  2000         Aaliyah            I Don't Wanna  4:15   7\n",
      "8  2000         Aaliyah                Try Again  4:03   8\n",
      "9  2000  Adams, Yolanda            Open My Heart  5:30   9\n"
     ]
    }
   ],
   "source": [
    "#중복 제거 데이터프레임에 아이디(id) 추가 > 데이터 조회/구분을 쉽게 할수 있도록\n",
    "billboard_songs['id'] = range(len(billboard_songs))\n",
    "print(billboard_songs.head(n=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24092, 8)\n",
      "       year           artist                    track  time date.entered  \\\n",
      "0      2000            2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26   \n",
      "1      2000            2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26   \n",
      "2      2000            2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26   \n",
      "3      2000            2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26   \n",
      "4      2000            2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26   \n",
      "...     ...              ...                      ...   ...          ...   \n",
      "24087  2000  matchbox twenty                     Bent  4:12   2000-04-29   \n",
      "24088  2000  matchbox twenty                     Bent  4:12   2000-04-29   \n",
      "24089  2000  matchbox twenty                     Bent  4:12   2000-04-29   \n",
      "24090  2000  matchbox twenty                     Bent  4:12   2000-04-29   \n",
      "24091  2000  matchbox twenty                     Bent  4:12   2000-04-29   \n",
      "\n",
      "       week  rating   id  \n",
      "0       wk1    87.0    0  \n",
      "1       wk2    82.0    0  \n",
      "2       wk3    72.0    0  \n",
      "3       wk4    77.0    0  \n",
      "4       wk5    87.0    0  \n",
      "...     ...     ...  ...  \n",
      "24087  wk72     NaN  316  \n",
      "24088  wk73     NaN  316  \n",
      "24089  wk74     NaN  316  \n",
      "24090  wk75     NaN  316  \n",
      "24091  wk76     NaN  316  \n",
      "\n",
      "[24092 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "#merge로 노래정보와 주간순위데이터 합침\n",
    "billboard_ratings = billboard_long.merge(billboard_songs, on=['year', 'artist', 'track', 'time'])\n",
    "print(billboard_ratings.shape)\n",
    "print(billboard_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-5 대용량 데이터 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 여러개로 나누어진 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://s3.amazonaws.com/nyc-tlc/csv_backup/fhv_tripdata_2015-01.csv\n",
      "\n",
      "./data\\fhv_tripdata_2015-01.csv\n",
      "https://s3.amazonaws.com/nyc-tlc/csv_backup/fhv_tripdata_2015-02.csv\n",
      "\n",
      "./data\\fhv_tripdata_2015-02.csv\n",
      "https://s3.amazonaws.com/nyc-tlc/csv_backup/fhv_tripdata_2015-03.csv\n",
      "\n",
      "./data\\fhv_tripdata_2015-03.csv\n",
      "https://s3.amazonaws.com/nyc-tlc/csv_backup/fhv_tripdata_2015-04.csv\n",
      "\n",
      "./data\\fhv_tripdata_2015-04.csv\n",
      "https://s3.amazonaws.com/nyc-tlc/csv_backup/fhv_tripdata_2015-05.csv\n",
      "\n",
      "./data\\fhv_tripdata_2015-05.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "with open('./data/raw_data_urls2.txt', 'r') as data_urls:\n",
    "    for line, url in enumerate(data_urls):\n",
    "        if line == 5:   #5개만 내려받음\n",
    "            break\n",
    "        fn = url.split('/')[-1].strip() #'/'단위로 나누고 앞뒤 공백제거(strip)\n",
    "        fp = os.path.join('', './data', fn) #파일 저장 경로 및 제목\n",
    "        print(url)\n",
    "        print(fp)\n",
    "        urllib.request.urlretrieve(url, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./data\\\\fhv_tripdata_2015-01.csv', './data\\\\fhv_tripdata_2015-02.csv', './data\\\\fhv_tripdata_2015-03.csv', './data\\\\fhv_tripdata_2015-04.csv', './data\\\\fhv_tripdata_2015-05.csv']\n"
     ]
    }
   ],
   "source": [
    "#glob메서드 : 패턴이 동일한 파일들을 한번에 읽어들일 수 있음\n",
    "import glob\n",
    "nyc_taxi_data = glob.glob('./data/fhv_*')\n",
    "print(nyc_taxi_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#각 파일 데이터프레임화\n",
    "taxi1 = pd.read_csv(nyc_taxi_data[0])\n",
    "taxi2 = pd.read_csv(nyc_taxi_data[1])\n",
    "taxi3 = pd.read_csv(nyc_taxi_data[2])\n",
    "taxi4 = pd.read_csv(nyc_taxi_data[3])\n",
    "taxi5 = pd.read_csv(nyc_taxi_data[4])\n",
    "    #이거 for문으로 못하나? global 변수선언 말고\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Dispatching_base_num          Pickup_date  locationID\n",
      "0               B00013  2015-01-01 00:30:00         NaN\n",
      "1               B00013  2015-01-01 01:22:00         NaN\n",
      "  Dispatching_base_num          Pickup_date  locationID\n",
      "0               B00013  2015-02-01 00:00:00         NaN\n",
      "1               B00013  2015-02-01 00:01:00         NaN\n",
      "  Dispatching_base_num          Pickup_date  locationID\n",
      "0               B00029  2015-03-01 00:02:00       213.0\n",
      "1               B00029  2015-03-01 00:03:00        51.0\n",
      "  Dispatching_base_num          Pickup_date  locationID\n",
      "0               B00001  2015-04-01 04:30:00         NaN\n",
      "1               B00001  2015-04-01 06:00:00         NaN\n",
      "  Dispatching_base_num          Pickup_date  locationID\n",
      "0               B00001  2015-05-01 04:30:00         NaN\n",
      "1               B00001  2015-05-01 05:00:00         NaN\n"
     ]
    }
   ],
   "source": [
    "print(taxi1.head(n=2))\n",
    "print(taxi2.head(n=2))\n",
    "print(taxi3.head(n=2))\n",
    "print(taxi4.head(n=2))\n",
    "print(taxi5.head(n=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2746033, 3)\n",
      "(3126401, 3)\n",
      "(3281427, 3)\n",
      "(3917789, 3)\n",
      "(4296067, 3)\n"
     ]
    }
   ],
   "source": [
    "#데이터의 구조(행, 열)이 규모가 큼\n",
    "print(taxi1.shape)\n",
    "print(taxi2.shape)\n",
    "print(taxi3.shape)\n",
    "print(taxi4.shape)\n",
    "print(taxi5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17367717, 3)\n"
     ]
    }
   ],
   "source": [
    "#데이터 전처리를 위해 각 데이터 프레임 연결\n",
    "taxi = pd.concat([taxi1, taxi2, taxi3, taxi4, taxi5])\n",
    "print(taxi.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 반복문으로 데이터 준비하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./data\\\\fhv_tripdata_2015-01.csv', './data\\\\fhv_tripdata_2015-02.csv', './data\\\\fhv_tripdata_2015-03.csv', './data\\\\fhv_tripdata_2015-04.csv', './data\\\\fhv_tripdata_2015-05.csv']\n",
      "./data\\fhv_tripdata_2015-01.csv\n",
      "./data\\fhv_tripdata_2015-02.csv\n",
      "./data\\fhv_tripdata_2015-03.csv\n",
      "./data\\fhv_tripdata_2015-04.csv\n",
      "./data\\fhv_tripdata_2015-05.csv\n",
      "5\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "nyc_taxi_data = glob.glob('./data/fhv_*')\n",
    "print(nyc_taxi_data)\n",
    "\n",
    "#반복문을 응용하면 단 몇줄로 데이터를 준비할 수 있음\n",
    "list_taxi_df = []\n",
    "for csv_filename in nyc_taxi_data:\n",
    "    print(csv_filename)\n",
    "    df = pd.read_csv(csv_filename)\n",
    "    list_taxi_df.append(df)\n",
    "    \n",
    "print(len(list_taxi_df))\n",
    "print(type(list_taxi_df[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Dispatching_base_num          Pickup_date  locationID\n",
      "0               B00013  2015-01-01 00:30:00         NaN\n",
      "1               B00013  2015-01-01 01:22:00         NaN\n",
      "2               B00013  2015-01-01 01:23:00         NaN\n",
      "3               B00013  2015-01-01 01:44:00         NaN\n",
      "4               B00013  2015-01-01 02:00:00         NaN\n"
     ]
    }
   ],
   "source": [
    "print(list_taxi_df[0].head())   #list_taxi_df리스트안에 5개의 df이 들어있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17367717, 3)\n"
     ]
    }
   ],
   "source": [
    "taxi_loop_concat = pd.concat(list_taxi_df)\n",
    "print(taxi_loop_concat.shape)   #리스트 5개로 세분되어있는 list_taxi_df를 concat으로 하나로 합침"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(taxi.equals(taxi_loop_concat))    #위에서 따로 담아 합친 taxi와의 데이터 비교"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "800fc19d2b578b3cea7f95541b40e86ff3796b71a0567e3a83f75cf2f90a080c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
